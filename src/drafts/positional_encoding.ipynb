{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torch.nn as nn \n",
    "\n",
    "from dataset import TransformerDataset, get_indices_entire_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FCR_N_PriceEUR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00+00:00</th>\n",
       "      <td>62.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00+00:00</th>\n",
       "      <td>62.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00+00:00</th>\n",
       "      <td>62.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00+00:00</th>\n",
       "      <td>62.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00+00:00</th>\n",
       "      <td>61.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FCR_N_PriceEUR\n",
       "timestamp                                \n",
       "2017-01-01 00:00:00+00:00           62.13\n",
       "2017-01-01 01:00:00+00:00           62.08\n",
       "2017-01-01 02:00:00+00:00           62.07\n",
       "2017-01-01 03:00:00+00:00           62.01\n",
       "2017-01-01 04:00:00+00:00           61.90"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"covid_data.csv\")\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "# df[\"FCR_N_PriceEUR2\"] = df[\"FCR_N_PriceEUR\"] ** 2\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "step_size = 1\n",
    "input_variables = [\"FCR_N_PriceEUR\"]\n",
    "input_size = len(input_variables)\n",
    "dec_seq_len = 92\n",
    "enc_seq_len = 153\n",
    "output_sequence_length = 48\n",
    "window_size = enc_seq_len + output_sequence_length \n",
    "batch_size = 128\n",
    "batch_first = False\n",
    "\n",
    "hidden_size = 1\n",
    "\n",
    "# Remove test data from dataset\n",
    "training_data = df[:-(round(len(df)*test_size))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From get_src_trg: data size = torch.Size([37248, 1])\n"
     ]
    }
   ],
   "source": [
    "# make list of (start_idx, end_idx) pairs that are used to slice the time series sequence into chunkc. \n",
    "# Should be training data indices only\n",
    "training_indices = get_indices_entire_sequence(data=training_data,\n",
    "                                               window_size=window_size, \n",
    "                                               step_size=step_size)\n",
    "\n",
    "# make instance of custom dataset class\n",
    "training_data = TransformerDataset(data=torch.tensor(training_data[input_variables].values).float(),\n",
    "                                   indices=training_indices,\n",
    "                                   enc_seq_len=enc_seq_len,\n",
    "                                   dec_seq_len=dec_seq_len,\n",
    "                                   target_seq_len=output_sequence_length)\n",
    "\n",
    "# make dataloader\n",
    "training_data = DataLoader(training_data, batch_size)\n",
    "\n",
    "# choose batch and get src, trg's\n",
    "i, batch = next(enumerate(training_data))\n",
    "src, trg, trg_y = batch\n",
    "\n",
    "# permute if batch_first == False\n",
    "if batch_first == False:\n",
    "    shape_before = src.shape\n",
    "    src = src.permute(1, 0, 2)\n",
    "\n",
    "    shape_before = trg.shape\n",
    "    trg = trg.permute(1, 0, 2)\n",
    "\n",
    "# define ffnn for the embedding dimension\n",
    "encoder_input_layer = nn.Linear(\n",
    "    in_features=input_size, \n",
    "    out_features=hidden_size \n",
    "    )\n",
    "\n",
    "# generate embedding dimension from src\n",
    "x = encoder_input_layer(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch_size, seq_len, hidden_size]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([153, 128, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[batch_size, seq_len, hidden_size]\")\n",
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch_size, seq_len, hidden_size]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([153, 128, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[batch_size, seq_len, hidden_size]\")\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = hidden_size\n",
    "max_seq_len = 500\n",
    "dropout = 0.1\n",
    "\n",
    "position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "nndropout = nn.Dropout(p=dropout)  \n",
    "\n",
    "if batch_first:\n",
    "    pe = torch.zeros(1, max_seq_len, d_model)\n",
    "    pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "    pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "else:\n",
    "    pe = torch.zeros(max_seq_len, 1, d_model)\n",
    "    pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "if batch_first:\n",
    "    new_x = x + pe[:,:x.size(1)]\n",
    "else:\n",
    "    new_x = x + pe[:x.size(0)]\n",
    "\n",
    "out = nndropout(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([153, 128, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([153, 1, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:x.size(0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-47.1080,  49.9145],\n",
       "        [-47.0695,  49.8746],\n",
       "        [-47.0618,  49.8666],\n",
       "        [-47.0156,  49.8187],\n",
       "        [-46.9308,  49.7310],\n",
       "        [-46.7074,  49.4996],\n",
       "        [-19.0171,  20.8243],\n",
       "        [-13.8551,  15.4786],\n",
       "        [-12.3527,  13.9228],\n",
       "        [-12.1138,  13.6754],\n",
       "        [-12.2833,  13.8510],\n",
       "        [-12.3373,  13.9068],\n",
       "        [-12.1369,  13.6994],\n",
       "        [-11.4743,  13.0132],\n",
       "        [-11.4281,  12.9653],\n",
       "        [-11.6361,  13.1808],\n",
       "        [-11.6516,  13.1967],\n",
       "        [-11.8519,  13.4042],\n",
       "        [-11.4821,  13.0212],\n",
       "        [-11.4666,  13.0052],\n",
       "        [-12.5145,  14.0903],\n",
       "        [-17.3915,  19.1408],\n",
       "        [-16.8907,  18.6222],\n",
       "        [-38.1091,  40.5954],\n",
       "        [-45.3899,  48.1352],\n",
       "        [-45.1433,  47.8799],\n",
       "        [-45.1665,  47.9039],\n",
       "        [-44.7350,  47.4571],\n",
       "        [-35.2507,  37.6353],\n",
       "        [-36.3755,  38.8002],\n",
       "        [-20.7892,  22.6594],\n",
       "        [-10.9658,  12.4866],\n",
       "        [-10.9581,  12.4786],\n",
       "        [-10.8965,  12.4148],\n",
       "        [-10.8811,  12.3989],\n",
       "        [-10.7809,  12.2951],\n",
       "        [-10.7809,  12.2951],\n",
       "        [-10.6268,  12.1356],\n",
       "        [-10.6423,  12.1515],\n",
       "        [-10.7193,  12.2313],\n",
       "        [-10.7578,  12.2712],\n",
       "        [-10.8734,  12.3909],\n",
       "        [-10.7886,  12.3031],\n",
       "        [-10.8041,  12.3191],\n",
       "        [-11.4358,  12.9733],\n",
       "        [-14.5793,  16.2286],\n",
       "        [-14.6640,  16.3164],\n",
       "        [-34.6882,  37.0529],\n",
       "        [-34.7345,  37.1008],\n",
       "        [-34.6805,  37.0449],\n",
       "        [-34.7268,  37.0928],\n",
       "        [-43.2942,  45.9650],\n",
       "        [-40.0506,  42.6060],\n",
       "        [-33.5403,  35.8641],\n",
       "        [-21.2360,  23.1222],\n",
       "        [-10.4111,  11.9122],\n",
       "        [-10.4111,  11.9122],\n",
       "        [-10.4342,  11.9361],\n",
       "        [-10.4342,  11.9361],\n",
       "        [-10.4265,  11.9281],\n",
       "        [-10.4111,  11.9122],\n",
       "        [-10.3033,  11.8005],\n",
       "        [-10.3572,  11.8563],\n",
       "        [-10.3495,  11.8483],\n",
       "        [-10.4805,  11.9840],\n",
       "        [-10.5960,  12.1036],\n",
       "        [-10.6577,  12.1675],\n",
       "        [-10.8272,  12.3430],\n",
       "        [-12.3450,  13.9148],\n",
       "        [-14.2942,  15.9334],\n",
       "        [-13.9398,  15.5664],\n",
       "        [-41.5761,  44.1858],\n",
       "        [-41.7764,  44.3932],\n",
       "        [-41.7148,  44.3294],\n",
       "        [-41.7842,  44.4012],\n",
       "        [-42.1000,  44.7284],\n",
       "        [-38.0089,  40.4917],\n",
       "        [-34.2645,  36.6141],\n",
       "        [-17.3452,  19.0929],\n",
       "        [-17.2759,  19.0211],\n",
       "        [ -9.7177,  11.1941],\n",
       "        [ -9.7793,  11.2579],\n",
       "        [ -9.7948,  11.2739],\n",
       "        [ -9.7639,  11.2419],\n",
       "        [ -9.7948,  11.2739],\n",
       "        [ -9.7485,  11.2260],\n",
       "        [ -9.7331,  11.2100],\n",
       "        [ -9.7331,  11.2100],\n",
       "        [ -9.7408,  11.2180],\n",
       "        [ -9.8564,  11.3377],\n",
       "        [ -9.9334,  11.4175],\n",
       "        [ -9.7023,  11.1781],\n",
       "        [-11.4435,  12.9813],\n",
       "        [-14.2018,  15.8377],\n",
       "        [-13.9167,  15.5424],\n",
       "        [-40.6439,  43.2204],\n",
       "        [-36.8917,  39.3348],\n",
       "        [-36.7145,  39.1513],\n",
       "        [-36.8301,  39.2710],\n",
       "        [-41.1909,  43.7869],\n",
       "        [-40.9752,  43.5635],\n",
       "        [-37.2693,  39.7257],\n",
       "        [-17.6380,  19.3961],\n",
       "        [-17.7844,  19.5477],\n",
       "        [-10.2801,  11.7765],\n",
       "        [-10.2570,  11.7526],\n",
       "        [-10.2493,  11.7446],\n",
       "        [-10.3649,  11.8643],\n",
       "        [-10.1723,  11.6648],\n",
       "        [-10.3726,  11.8723],\n",
       "        [-10.2031,  11.6967],\n",
       "        [-10.3341,  11.8324],\n",
       "        [-10.0182,  11.5052],\n",
       "        [-10.1338,  11.6249],\n",
       "        [-10.0952,  11.5850],\n",
       "        [ -9.9334,  11.4175],\n",
       "        [-11.5283,  13.0691],\n",
       "        [-15.3420,  17.0185],\n",
       "        [-15.2034,  16.8749],\n",
       "        [-39.7424,  42.2869],\n",
       "        [-34.9810,  37.3561],\n",
       "        [-36.8378,  39.2789],\n",
       "        [-37.1922,  39.6460],\n",
       "        [-37.1999,  39.6539],\n",
       "        [-39.7578,  42.3028],\n",
       "        [-35.7284,  38.1300],\n",
       "        [-14.9106,  16.5717],\n",
       "        [-14.6101,  16.2605]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx, bpe = torch.broadcast_tensors(x, pe[:x.size(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-47.1080,  49.9145],\n",
       "        [-47.0695,  49.8746],\n",
       "        [-47.0618,  49.8666],\n",
       "        [-47.0156,  49.8187],\n",
       "        [-46.9308,  49.7310],\n",
       "        [-46.7074,  49.4996],\n",
       "        [-19.0171,  20.8243],\n",
       "        [-13.8551,  15.4786],\n",
       "        [-12.3527,  13.9228],\n",
       "        [-12.1138,  13.6754],\n",
       "        [-12.2833,  13.8510],\n",
       "        [-12.3373,  13.9068],\n",
       "        [-12.1369,  13.6994],\n",
       "        [-11.4743,  13.0132],\n",
       "        [-11.4281,  12.9653],\n",
       "        [-11.6361,  13.1808],\n",
       "        [-11.6516,  13.1967],\n",
       "        [-11.8519,  13.4042],\n",
       "        [-11.4821,  13.0212],\n",
       "        [-11.4666,  13.0052],\n",
       "        [-12.5145,  14.0903],\n",
       "        [-17.3915,  19.1408],\n",
       "        [-16.8907,  18.6222],\n",
       "        [-38.1091,  40.5954],\n",
       "        [-45.3899,  48.1352],\n",
       "        [-45.1433,  47.8799],\n",
       "        [-45.1665,  47.9039],\n",
       "        [-44.7350,  47.4571],\n",
       "        [-35.2507,  37.6353],\n",
       "        [-36.3755,  38.8002],\n",
       "        [-20.7892,  22.6594],\n",
       "        [-10.9658,  12.4866],\n",
       "        [-10.9581,  12.4786],\n",
       "        [-10.8965,  12.4148],\n",
       "        [-10.8811,  12.3989],\n",
       "        [-10.7809,  12.2951],\n",
       "        [-10.7809,  12.2951],\n",
       "        [-10.6268,  12.1356],\n",
       "        [-10.6423,  12.1515],\n",
       "        [-10.7193,  12.2313],\n",
       "        [-10.7578,  12.2712],\n",
       "        [-10.8734,  12.3909],\n",
       "        [-10.7886,  12.3031],\n",
       "        [-10.8041,  12.3191],\n",
       "        [-11.4358,  12.9733],\n",
       "        [-14.5793,  16.2286],\n",
       "        [-14.6640,  16.3164],\n",
       "        [-34.6882,  37.0529],\n",
       "        [-34.7345,  37.1008],\n",
       "        [-34.6805,  37.0449],\n",
       "        [-34.7268,  37.0928],\n",
       "        [-43.2942,  45.9650],\n",
       "        [-40.0506,  42.6060],\n",
       "        [-33.5403,  35.8641],\n",
       "        [-21.2360,  23.1222],\n",
       "        [-10.4111,  11.9122],\n",
       "        [-10.4111,  11.9122],\n",
       "        [-10.4342,  11.9361],\n",
       "        [-10.4342,  11.9361],\n",
       "        [-10.4265,  11.9281],\n",
       "        [-10.4111,  11.9122],\n",
       "        [-10.3033,  11.8005],\n",
       "        [-10.3572,  11.8563],\n",
       "        [-10.3495,  11.8483],\n",
       "        [-10.4805,  11.9840],\n",
       "        [-10.5960,  12.1036],\n",
       "        [-10.6577,  12.1675],\n",
       "        [-10.8272,  12.3430],\n",
       "        [-12.3450,  13.9148],\n",
       "        [-14.2942,  15.9334],\n",
       "        [-13.9398,  15.5664],\n",
       "        [-41.5761,  44.1858],\n",
       "        [-41.7764,  44.3932],\n",
       "        [-41.7148,  44.3294],\n",
       "        [-41.7842,  44.4012],\n",
       "        [-42.1000,  44.7284],\n",
       "        [-38.0089,  40.4917],\n",
       "        [-34.2645,  36.6141],\n",
       "        [-17.3452,  19.0929],\n",
       "        [-17.2759,  19.0211],\n",
       "        [ -9.7177,  11.1941],\n",
       "        [ -9.7793,  11.2579],\n",
       "        [ -9.7948,  11.2739],\n",
       "        [ -9.7639,  11.2419],\n",
       "        [ -9.7948,  11.2739],\n",
       "        [ -9.7485,  11.2260],\n",
       "        [ -9.7331,  11.2100],\n",
       "        [ -9.7331,  11.2100],\n",
       "        [ -9.7408,  11.2180],\n",
       "        [ -9.8564,  11.3377],\n",
       "        [ -9.9334,  11.4175],\n",
       "        [ -9.7023,  11.1781],\n",
       "        [-11.4435,  12.9813],\n",
       "        [-14.2018,  15.8377],\n",
       "        [-13.9167,  15.5424],\n",
       "        [-40.6439,  43.2204],\n",
       "        [-36.8917,  39.3348],\n",
       "        [-36.7145,  39.1513],\n",
       "        [-36.8301,  39.2710],\n",
       "        [-41.1909,  43.7869],\n",
       "        [-40.9752,  43.5635],\n",
       "        [-37.2693,  39.7257],\n",
       "        [-17.6380,  19.3961],\n",
       "        [-17.7844,  19.5477],\n",
       "        [-10.2801,  11.7765],\n",
       "        [-10.2570,  11.7526],\n",
       "        [-10.2493,  11.7446],\n",
       "        [-10.3649,  11.8643],\n",
       "        [-10.1723,  11.6648],\n",
       "        [-10.3726,  11.8723],\n",
       "        [-10.2031,  11.6967],\n",
       "        [-10.3341,  11.8324],\n",
       "        [-10.0182,  11.5052],\n",
       "        [-10.1338,  11.6249],\n",
       "        [-10.0952,  11.5850],\n",
       "        [ -9.9334,  11.4175],\n",
       "        [-11.5283,  13.0691],\n",
       "        [-15.3420,  17.0185],\n",
       "        [-15.2034,  16.8749],\n",
       "        [-39.7424,  42.2869],\n",
       "        [-34.9810,  37.3561],\n",
       "        [-36.8378,  39.2789],\n",
       "        [-37.1922,  39.6460],\n",
       "        [-37.1999,  39.6539],\n",
       "        [-39.7578,  42.3028],\n",
       "        [-35.7284,  38.1300],\n",
       "        [-14.9106,  16.5717],\n",
       "        [-14.6101,  16.2605]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd-ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
