{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from data_loaders import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(root_path, \"data\")\n",
    "\n",
    "# inputs and outputs parameters\n",
    "model_name = \"transformer_encoder_mlp_decoder\"\n",
    "device = \"cpu\"\n",
    "dataset_name = \"springs\"\n",
    "num_atoms = 5\n",
    "temperature = 0.1\n",
    "length = 1000\n",
    "num_samples = 1000\n",
    "n_lags = None\n",
    "\n",
    "# training parameters\n",
    "n_epochs = 500\n",
    "learning_rate = 5e-4\n",
    "batch_size = 256\n",
    "batch_first = True\n",
    "input_size = num_atoms\n",
    "embedd_hidden_size = 100\n",
    "\n",
    "suffix = \"_\" + dataset_name + str(num_atoms)\n",
    "\n",
    "if (temperature is not None):\n",
    "    suffix += \"_inter\" + str(temperature)\n",
    "\n",
    "if (length is not None):\n",
    "    suffix += \"_l\" + str(length)\n",
    "\n",
    "if num_samples != 50000:\n",
    "    suffix += \"_s\" + str(num_samples)\n",
    "\n",
    "if n_lags is not None:\n",
    "    suffix += \"_lag\" + str(n_lags)\n",
    "\n",
    "## load data\n",
    "train_dataset = load_data(root_dir=os.path.join(data_path, dataset_name),\n",
    "                            suffix=suffix,\n",
    "                            num_atoms=num_atoms)\n",
    "\n",
    "# NOTE: Random sampling occurs in the \"num_sample\" dimension instead of \"num_obs\"\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# choose batch and get src, trg's\n",
    "i, (features, gt_edges)  = next(enumerate(train_loader))\n",
    "\n",
    "# reshape features from graph-type data to timeseries-type data\n",
    "graph_features = features.reshape(features.shape[0], features.shape[2] * features.shape[3], features.shape[1])\n",
    "\n",
    "src = graph_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch_size, num_objects, num_timesteps, num_feature_per_objects]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 5, 9, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[batch_size, num_objects, num_timesteps, num_feature_per_objects]\")\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch_size, num_timesteps * num_feature_per_objects, num_objects]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 36, 5])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[batch_size, num_timesteps * num_feature_per_objects, num_objects]\")\n",
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute if batch_first == False\n",
    "if batch_first == False:\n",
    "    shape_before = src.shape\n",
    "    src = src.permute(1, 0, 2)\n",
    "\n",
    "# define ffnn for the embedding dimension\n",
    "encoder_input_layer = nn.Linear(\n",
    "    in_features=input_size, \n",
    "    out_features=embedd_hidden_size \n",
    "    )\n",
    "\n",
    "# generate embedding dimension from src\n",
    "x = encoder_input_layer(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch_size, num_timesteps * num_feature_per_objects, num_embeddings]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 36, 100])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[batch_size, num_timesteps * num_feature_per_objects, num_embeddings]\")\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = embedd_hidden_size\n",
    "max_seq_len = 500\n",
    "dropout = 0.1\n",
    "\n",
    "position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "nndropout = nn.Dropout(p=dropout)  \n",
    "\n",
    "if batch_first:\n",
    "    pe = torch.zeros(1, max_seq_len, d_model)\n",
    "    pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "    pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "else:\n",
    "    pe = torch.zeros(max_seq_len, 1, d_model)\n",
    "    pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "if batch_first:\n",
    "    new_x = x + pe[:,:x.size(1)]\n",
    "else:\n",
    "    new_x = x + pe[:x.size(0)]\n",
    "\n",
    "out = nndropout(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ x: torch.Size([256, 36, 100]) + pe: torch.Size([1, 36, 100]) } = new_x: torch.Size([256, 36, 100])\n"
     ]
    }
   ],
   "source": [
    "print(\"{ x:\", x.shape, \"+ pe:\", pe[:,:x.size(1)].shape, \"} = new_x:\", new_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd-ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
