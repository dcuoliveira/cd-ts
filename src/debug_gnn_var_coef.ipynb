{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read financial time series simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_code = os.path.join(os.getcwd())\n",
    "data_files = os.path.join(source_code, \"data\")\n",
    "\n",
    "dgp_simulations = os.listdir(os.path.join(data_files, \"simulation\"))\n",
    "\n",
    "dgp_name = dgp_simulations[0]\n",
    "dgp_name_summary = \"_\".join(dgp_name.split(\".\")[0].split(\"_\")[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>0.574134</td>\n",
       "      <td>1.185314</td>\n",
       "      <td>-2.135221</td>\n",
       "      <td>1.396963</td>\n",
       "      <td>1.465781</td>\n",
       "      <td>0.379528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>-0.346110</td>\n",
       "      <td>0.376818</td>\n",
       "      <td>-1.202009</td>\n",
       "      <td>0.286999</td>\n",
       "      <td>-0.301319</td>\n",
       "      <td>-0.656244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>-1.347234</td>\n",
       "      <td>1.170678</td>\n",
       "      <td>-0.849348</td>\n",
       "      <td>-1.447754</td>\n",
       "      <td>0.700321</td>\n",
       "      <td>-2.309333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>0.089634</td>\n",
       "      <td>-0.789695</td>\n",
       "      <td>1.136106</td>\n",
       "      <td>-1.240626</td>\n",
       "      <td>0.695460</td>\n",
       "      <td>-0.111975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>-0.452691</td>\n",
       "      <td>1.485636</td>\n",
       "      <td>-0.309389</td>\n",
       "      <td>1.293701</td>\n",
       "      <td>1.811287</td>\n",
       "      <td>0.118102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5\n",
       "1178  0.574134  1.185314 -2.135221  1.396963  1.465781  0.379528\n",
       "1179 -0.346110  0.376818 -1.202009  0.286999 -0.301319 -0.656244\n",
       "1180 -1.347234  1.170678 -0.849348 -1.447754  0.700321 -2.309333\n",
       "1181  0.089634 -0.789695  1.136106 -1.240626  0.695460 -0.111975\n",
       "1182 -0.452691  1.485636 -0.309389  1.293701  1.811287  0.118102"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets_features = pd.read_csv(os.path.join(data_files, \"simulation\", dgp_simulations[0]), sep=\",\")\n",
    "rets_features.columns = list(range(0, rets_features.shape[1]))\n",
    "\n",
    "rets_features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075060</td>\n",
       "      <td>0.067476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.074032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047014</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008524</td>\n",
       "      <td>0.01979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040917</td>\n",
       "      <td>0.030609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>-0.013911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006367</td>\n",
       "      <td>-0.004491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005070</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012265</td>\n",
       "      <td>-0.135449</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010694</td>\n",
       "      <td>-0.012266</td>\n",
       "      <td>-0.003466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.010765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004662</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.123139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025276</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.085288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.013864</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         6         7         8         9         10        11        12  \\\n",
       "1  0.015972  0.000000  0.075060  0.067476  0.000000 -0.074032  0.000000   \n",
       "2  0.000000  0.000000  0.040917  0.030609  0.000000  0.000000  0.000000   \n",
       "3  0.000000 -0.005070  0.016224  0.000000 -0.012265 -0.135449  0.004277   \n",
       "4  0.000000 -0.004662  0.001755  0.000000  0.000000 -0.123139  0.000000   \n",
       "5  0.000000  0.000000  0.025276  0.052771  0.000000 -0.085288  0.000000   \n",
       "\n",
       "         13        14        15  ...  38        39        40        41  \\\n",
       "1  0.000000  0.000000  0.047014  ...   0  0.000000  0.000000  0.000000   \n",
       "2  0.001067 -0.013911  0.000000  ...   0  0.000000 -0.006367 -0.004491   \n",
       "3  0.008169  0.000000  0.000000  ...   0 -0.010694 -0.012266 -0.003466   \n",
       "4  0.007864  0.000000  0.000000  ...   0  0.000000 -0.016150  0.000000   \n",
       "5  0.000000  0.000000  0.018136  ...   0  0.000000 -0.013864 -0.012383   \n",
       "\n",
       "         42       43  44  45        46        47  \n",
       "1 -0.008524  0.01979   0   0  0.000000  0.034991  \n",
       "2  0.000000  0.00000   0   0  0.000000  0.000000  \n",
       "3  0.000000  0.00000   0   0  0.003868  0.010765  \n",
       "4  0.000000  0.00000   0   0  0.000000  0.012223  \n",
       "5  0.000000  0.00000   0   0  0.000000  0.027859  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgp = pd.read_csv(os.path.join(data_files, \"DGP\", \"{}_B.csv\".format(dgp_name_summary)), sep=\",\")\n",
    "dgp.columns = list(range(dgp.shape[0], dgp.shape[1] + dgp.shape[0]))\n",
    "\n",
    "dgp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = int((dgp.shape[1] / rets_features.shape[1]))\n",
    "k = rets_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = k\n",
    "for i in range(1, p + 1):\n",
    "    for j in range(k):\n",
    "        rets_features[count] = rets_features[j].shift(i)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.993166</td>\n",
       "      <td>-0.849707</td>\n",
       "      <td>-0.333492</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.280819</td>\n",
       "      <td>-0.819419</td>\n",
       "      <td>0.172910</td>\n",
       "      <td>2.730090</td>\n",
       "      <td>1.259242</td>\n",
       "      <td>-0.996195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048810</td>\n",
       "      <td>-1.085705</td>\n",
       "      <td>-0.373970</td>\n",
       "      <td>0.938787</td>\n",
       "      <td>0.928701</td>\n",
       "      <td>0.694253</td>\n",
       "      <td>-2.646563</td>\n",
       "      <td>2.121203</td>\n",
       "      <td>-1.444718</td>\n",
       "      <td>1.143690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.384623</td>\n",
       "      <td>0.313387</td>\n",
       "      <td>0.422141</td>\n",
       "      <td>-0.449832</td>\n",
       "      <td>-0.048114</td>\n",
       "      <td>-0.179039</td>\n",
       "      <td>1.993166</td>\n",
       "      <td>-0.849707</td>\n",
       "      <td>-0.333492</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.368697</td>\n",
       "      <td>-0.875759</td>\n",
       "      <td>-1.114491</td>\n",
       "      <td>-0.819987</td>\n",
       "      <td>1.060805</td>\n",
       "      <td>0.161501</td>\n",
       "      <td>0.048810</td>\n",
       "      <td>-1.085705</td>\n",
       "      <td>-0.373970</td>\n",
       "      <td>0.938787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.648169</td>\n",
       "      <td>-0.772028</td>\n",
       "      <td>1.652056</td>\n",
       "      <td>1.670741</td>\n",
       "      <td>-0.109904</td>\n",
       "      <td>-0.572845</td>\n",
       "      <td>-0.384623</td>\n",
       "      <td>0.313387</td>\n",
       "      <td>0.422141</td>\n",
       "      <td>-0.449832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491147</td>\n",
       "      <td>-0.114345</td>\n",
       "      <td>0.601553</td>\n",
       "      <td>1.374663</td>\n",
       "      <td>0.849793</td>\n",
       "      <td>-1.979300</td>\n",
       "      <td>-1.368697</td>\n",
       "      <td>-0.875759</td>\n",
       "      <td>-1.114491</td>\n",
       "      <td>-0.819987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.372592</td>\n",
       "      <td>0.411914</td>\n",
       "      <td>0.981885</td>\n",
       "      <td>1.162538</td>\n",
       "      <td>-0.553074</td>\n",
       "      <td>-0.935610</td>\n",
       "      <td>0.648169</td>\n",
       "      <td>-0.772028</td>\n",
       "      <td>1.652056</td>\n",
       "      <td>1.670741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827680</td>\n",
       "      <td>1.014956</td>\n",
       "      <td>1.381708</td>\n",
       "      <td>1.509070</td>\n",
       "      <td>1.269280</td>\n",
       "      <td>-1.619266</td>\n",
       "      <td>0.491147</td>\n",
       "      <td>-0.114345</td>\n",
       "      <td>0.601553</td>\n",
       "      <td>1.374663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.036951</td>\n",
       "      <td>-0.241822</td>\n",
       "      <td>-1.031208</td>\n",
       "      <td>-1.508993</td>\n",
       "      <td>1.075138</td>\n",
       "      <td>0.517178</td>\n",
       "      <td>-1.372592</td>\n",
       "      <td>0.411914</td>\n",
       "      <td>0.981885</td>\n",
       "      <td>1.162538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107260</td>\n",
       "      <td>0.398302</td>\n",
       "      <td>0.470229</td>\n",
       "      <td>0.766541</td>\n",
       "      <td>-0.259359</td>\n",
       "      <td>0.608076</td>\n",
       "      <td>0.827680</td>\n",
       "      <td>1.014956</td>\n",
       "      <td>1.381708</td>\n",
       "      <td>1.509070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>0.574134</td>\n",
       "      <td>1.185314</td>\n",
       "      <td>-2.135221</td>\n",
       "      <td>1.396963</td>\n",
       "      <td>1.465781</td>\n",
       "      <td>0.379528</td>\n",
       "      <td>-0.080417</td>\n",
       "      <td>0.059763</td>\n",
       "      <td>1.436874</td>\n",
       "      <td>-0.751858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200426</td>\n",
       "      <td>-0.301025</td>\n",
       "      <td>1.055802</td>\n",
       "      <td>0.694533</td>\n",
       "      <td>1.286434</td>\n",
       "      <td>0.089988</td>\n",
       "      <td>-0.900003</td>\n",
       "      <td>0.284846</td>\n",
       "      <td>-0.339015</td>\n",
       "      <td>-0.140583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>-0.346110</td>\n",
       "      <td>0.376818</td>\n",
       "      <td>-1.202009</td>\n",
       "      <td>0.286999</td>\n",
       "      <td>-0.301319</td>\n",
       "      <td>-0.656244</td>\n",
       "      <td>0.574134</td>\n",
       "      <td>1.185314</td>\n",
       "      <td>-2.135221</td>\n",
       "      <td>1.396963</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461771</td>\n",
       "      <td>0.733303</td>\n",
       "      <td>1.446477</td>\n",
       "      <td>1.326655</td>\n",
       "      <td>-0.187439</td>\n",
       "      <td>0.350321</td>\n",
       "      <td>0.200426</td>\n",
       "      <td>-0.301025</td>\n",
       "      <td>1.055802</td>\n",
       "      <td>0.694533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>-1.347234</td>\n",
       "      <td>1.170678</td>\n",
       "      <td>-0.849348</td>\n",
       "      <td>-1.447754</td>\n",
       "      <td>0.700321</td>\n",
       "      <td>-2.309333</td>\n",
       "      <td>-0.346110</td>\n",
       "      <td>0.376818</td>\n",
       "      <td>-1.202009</td>\n",
       "      <td>0.286999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304604</td>\n",
       "      <td>0.664977</td>\n",
       "      <td>-0.753563</td>\n",
       "      <td>-0.893290</td>\n",
       "      <td>-0.737554</td>\n",
       "      <td>-0.829092</td>\n",
       "      <td>1.461771</td>\n",
       "      <td>0.733303</td>\n",
       "      <td>1.446477</td>\n",
       "      <td>1.326655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>0.089634</td>\n",
       "      <td>-0.789695</td>\n",
       "      <td>1.136106</td>\n",
       "      <td>-1.240626</td>\n",
       "      <td>0.695460</td>\n",
       "      <td>-0.111975</td>\n",
       "      <td>-1.347234</td>\n",
       "      <td>1.170678</td>\n",
       "      <td>-0.849348</td>\n",
       "      <td>-1.447754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124232</td>\n",
       "      <td>2.253571</td>\n",
       "      <td>-0.881236</td>\n",
       "      <td>-1.007719</td>\n",
       "      <td>-0.230120</td>\n",
       "      <td>-0.379963</td>\n",
       "      <td>-0.304604</td>\n",
       "      <td>0.664977</td>\n",
       "      <td>-0.753563</td>\n",
       "      <td>-0.893290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>-0.452691</td>\n",
       "      <td>1.485636</td>\n",
       "      <td>-0.309389</td>\n",
       "      <td>1.293701</td>\n",
       "      <td>1.811287</td>\n",
       "      <td>0.118102</td>\n",
       "      <td>0.089634</td>\n",
       "      <td>-0.789695</td>\n",
       "      <td>1.136106</td>\n",
       "      <td>-1.240626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375778</td>\n",
       "      <td>-0.848451</td>\n",
       "      <td>0.858643</td>\n",
       "      <td>-1.252129</td>\n",
       "      <td>0.649138</td>\n",
       "      <td>-0.002005</td>\n",
       "      <td>0.124232</td>\n",
       "      <td>2.253571</td>\n",
       "      <td>-0.881236</td>\n",
       "      <td>-1.007719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "7     1.993166 -0.849707 -0.333492  0.036613  0.280819 -0.819419  0.172910   \n",
       "8    -0.384623  0.313387  0.422141 -0.449832 -0.048114 -0.179039  1.993166   \n",
       "9     0.648169 -0.772028  1.652056  1.670741 -0.109904 -0.572845 -0.384623   \n",
       "10   -1.372592  0.411914  0.981885  1.162538 -0.553074 -0.935610  0.648169   \n",
       "11    1.036951 -0.241822 -1.031208 -1.508993  1.075138  0.517178 -1.372592   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1178  0.574134  1.185314 -2.135221  1.396963  1.465781  0.379528 -0.080417   \n",
       "1179 -0.346110  0.376818 -1.202009  0.286999 -0.301319 -0.656244  0.574134   \n",
       "1180 -1.347234  1.170678 -0.849348 -1.447754  0.700321 -2.309333 -0.346110   \n",
       "1181  0.089634 -0.789695  1.136106 -1.240626  0.695460 -0.111975 -1.347234   \n",
       "1182 -0.452691  1.485636 -0.309389  1.293701  1.811287  0.118102  0.089634   \n",
       "\n",
       "            7         8         9   ...        38        39        40  \\\n",
       "7     2.730090  1.259242 -0.996195  ...  0.048810 -1.085705 -0.373970   \n",
       "8    -0.849707 -0.333492  0.036613  ... -1.368697 -0.875759 -1.114491   \n",
       "9     0.313387  0.422141 -0.449832  ...  0.491147 -0.114345  0.601553   \n",
       "10   -0.772028  1.652056  1.670741  ...  0.827680  1.014956  1.381708   \n",
       "11    0.411914  0.981885  1.162538  ... -0.107260  0.398302  0.470229   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1178  0.059763  1.436874 -0.751858  ...  0.200426 -0.301025  1.055802   \n",
       "1179  1.185314 -2.135221  1.396963  ...  1.461771  0.733303  1.446477   \n",
       "1180  0.376818 -1.202009  0.286999  ... -0.304604  0.664977 -0.753563   \n",
       "1181  1.170678 -0.849348 -1.447754  ...  0.124232  2.253571 -0.881236   \n",
       "1182 -0.789695  1.136106 -1.240626  ...  0.375778 -0.848451  0.858643   \n",
       "\n",
       "            41        42        43        44        45        46        47  \n",
       "7     0.938787  0.928701  0.694253 -2.646563  2.121203 -1.444718  1.143690  \n",
       "8    -0.819987  1.060805  0.161501  0.048810 -1.085705 -0.373970  0.938787  \n",
       "9     1.374663  0.849793 -1.979300 -1.368697 -0.875759 -1.114491 -0.819987  \n",
       "10    1.509070  1.269280 -1.619266  0.491147 -0.114345  0.601553  1.374663  \n",
       "11    0.766541 -0.259359  0.608076  0.827680  1.014956  1.381708  1.509070  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1178  0.694533  1.286434  0.089988 -0.900003  0.284846 -0.339015 -0.140583  \n",
       "1179  1.326655 -0.187439  0.350321  0.200426 -0.301025  1.055802  0.694533  \n",
       "1180 -0.893290 -0.737554 -0.829092  1.461771  0.733303  1.446477  1.326655  \n",
       "1181 -1.007719 -0.230120 -0.379963 -0.304604  0.664977 -0.753563 -0.893290  \n",
       "1182 -1.252129  0.649138 -0.002005  0.124232  2.253571 -0.881236 -1.007719  \n",
       "\n",
       "[1176 rows x 48 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets_features = rets_features.dropna()\n",
    "\n",
    "rets_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176, 48)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieloliveira/opt/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)\n",
    "\n",
    "edge_index = torch.tensor([[0, 2, 1, 0, 3], [3, 1, 0, 1, 2]], dtype=torch.long)\n",
    "\n",
    "data = Data(x=x, y=y, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  1.],\n",
       "        [ 5.,  6.],\n",
       "        [ 3.,  7.],\n",
       "        [12.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 1, 0, 3],\n",
       "        [3, 1, 0, 1, 2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sketch of the graph dataset components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features\n",
    "x = torch.from_numpy(rets_features.to_numpy()).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lables\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = dgp.copy()\n",
    "\n",
    "# create adjacency matrix\n",
    "adj_matrix = np.where(edges.__abs__() != 0, 1, np.nan)\n",
    "adj = pd.DataFrame(adj_matrix, index=edges.index, columns=edges.columns).reset_index().melt(\"index\").dropna()\n",
    "\n",
    "# create edge index\n",
    "row = torch.from_numpy(adj.index.to_numpy().astype(np.int64)).to(torch.long)\n",
    "col = torch.from_numpy(adj.variable.to_numpy().astype(np.int64)).to(torch.long)\n",
    "edge_index = torch.stack([row, col], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1176, 48], edge_index=[2, 80])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(x=x, y=y, edge_index=edge_index)\n",
    "\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build GraphDataset class for time series simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE(torch.nn.Module):\n",
    "    def __init__(self, n_input, n_hidden_units, n_output):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(n_input, n_hidden_units)\n",
    "        self.conv2 = GCNConv(n_hidden_units, n_output)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_link_predictor(model, data):\n",
    "    \n",
    "    model.eval()\n",
    "    z = model.encode(x=data.x, edge_index=data.edge_index)\n",
    "\n",
    "    # sampling training negatives for every training epoch\n",
    "    neg_edge_index = negative_sampling(edge_index=data.edge_index,\n",
    "                                        num_nodes=data.num_nodes,\n",
    "                                        num_neg_samples=data.edge_label_index.size(1), \n",
    "                                        method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        data.edge_label,\n",
    "        data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z=z, edge_label_index=edge_label_index).view(-1).sigmoid()\n",
    "\n",
    "    return roc_auc_score(edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "# def train_link_predictor(model, train_data, val_data, optimizer, criterion, n_epochs=100):\n",
    "\n",
    "#     for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "#         z = model.encode(x=train_data.x, edge_index=train_data.edge_index)\n",
    "\n",
    "#         # sampling training negatives for every training epoch\n",
    "#         neg_edge_index = negative_sampling(edge_index=train_data.edge_index,\n",
    "#                                            num_nodes=train_data.num_nodes,\n",
    "#                                            num_neg_samples=train_data.edge_label_index.size(1), \n",
    "#                                            method='sparse')\n",
    "\n",
    "#         edge_label_index = torch.cat(\n",
    "#             [train_data.edge_label_index, neg_edge_index],\n",
    "#             dim=-1,\n",
    "#         )\n",
    "#         edge_label = torch.cat([\n",
    "#             train_data.edge_label,\n",
    "#             train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "#         ], dim=0)\n",
    "\n",
    "#         out = model.decode(z, edge_label_index).view(-1)\n",
    "#         loss = criterion(out, edge_label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         val_auc = eval_link_predictor(model, val_data)\n",
    "\n",
    "#         if epoch % 10 == 0:\n",
    "#             print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}\")\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    "    neg_sampling_ratio=1.0,\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   6,   9,  10,  12,  13,  14,  15,  16,  17,  18,  19,  20,\n",
       "          23,  27,  30,  31,  33,  34,  35,  39,  44,  45,  46,  50,  54,  55,\n",
       "          59,  69,  72,  74,  75,  78,  79,  81,  82,  83,  86,  92,  93, 120,\n",
       "         126, 138, 139, 150, 151, 152, 155, 158, 159, 160, 163, 165, 179, 180,\n",
       "         183, 184, 185, 186, 187, 190, 201, 206, 207, 208, 209, 212, 213, 215,\n",
       "         217, 222, 223, 240, 243, 246, 247, 249, 250, 251],\n",
       "        [  6,   6,   7,   7,   7,   8,   8,   8,   8,   8,   8,   9,   9,   9,\n",
       "           9,  10,  11,  11,  11,  11,  11,  12,  13,  13,  13,  14,  15,  15,\n",
       "          15,  17,  18,  18,  18,  19,  19,  19,  19,  19,  20,  21,  21,  26,\n",
       "          27,  29,  29,  31,  31,  31,  31,  32,  32,  32,  33,  33,  35,  36,\n",
       "          36,  36,  36,  37,  37,  37,  39,  40,  40,  40,  40,  41,  41,  41,\n",
       "          42,  43,  43,  46,  46,  47,  47,  47,  47,  47]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 6, 6, 6, 7],\n",
       "        [6, 6, 7, 1, 0, 6]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 6, 6, 6, 7],\n",
       "        [6, 6, 7, 1, 0, 6]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 6, 6, 6, 7],\n",
       "        [6, 6, 7, 1, 0, 6]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(n_input=x.shape[1],\n",
    "             n_hidden_units=128,\n",
    "             n_output=64).to(\"cpu\")\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "n_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "z = model.encode(x=train_data.x, edge_index=train_data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling training negatives for every training epoch\n",
    "neg_edge_index = negative_sampling(edge_index=train_data.edge_index,\n",
    "                                    num_nodes=train_data.num_nodes,\n",
    "                                    num_neg_samples=train_data.edge_label_index.size(1), \n",
    "                                    method='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label_index = torch.cat(\n",
    "    [train_data.edge_label_index, neg_edge_index],\n",
    "    dim=-1,\n",
    ")\n",
    "edge_label = torch.cat([\n",
    "    train_data.edge_label,\n",
    "    train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.decode(z, edge_label_index).view(-1)\n",
    "loss = criterion(out, edge_label)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z = model.encode(x=val_data.x, edge_index=val_data.edge_index)\n",
    "\n",
    "# sampling training negatives for every training epoch\n",
    "neg_edge_index = negative_sampling(edge_index=val_data.edge_index,\n",
    "                                    num_nodes=val_data.num_nodes,\n",
    "                                    num_neg_samples=val_data.edge_label_index.size(1), \n",
    "                                    method='sparse')\n",
    "\n",
    "edge_label_index = torch.cat(\n",
    "    [val_data.edge_label_index, neg_edge_index],\n",
    "    dim=-1,\n",
    ")\n",
    "edge_label = torch.cat([\n",
    "    val_data.edge_label,\n",
    "    val_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.edge_label_index.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdecode(z\u001b[39m=\u001b[39;49mz, edge_label_index\u001b[39m=\u001b[39;49medge_label_index)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msigmoid()\n",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m, in \u001b[0;36mVGAE.decode\u001b[0;34m(self, z, edge_label_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, z, edge_label_index):\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m (z[edge_label_index[\u001b[39m0\u001b[39;49m]] \u001b[39m*\u001b[39m z[edge_label_index[\u001b[39m1\u001b[39m]])\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "out = model.decode(z=z, edge_label_index=edge_label_index).view(-1).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     25\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 27\u001b[0m val_auc \u001b[39m=\u001b[39m eval_link_predictor(model, val_data)\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Val AUC: \u001b[39m\u001b[39m{\u001b[39;00mval_auc\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m, in \u001b[0;36meval_link_predictor\u001b[0;34m(model, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m z \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode(x\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mx, edge_index\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39medge_index)\n\u001b[1;32m     23\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecode(z\u001b[39m=\u001b[39mz, edge_label_index\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39medge_label_index)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msigmoid()\n\u001b[0;32m---> 25\u001b[0m \u001b[39mreturn\u001b[39;00m roc_auc_score(data\u001b[39m.\u001b[39;49medge_label\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy(), out\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:550\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) \\\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[39mfrom prediction scores.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39marray([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    549\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 550\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    551\u001b[0m y_score \u001b[39m=\u001b[39m check_array(y_score, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    553\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    554\u001b[0m     y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m y_score\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y_score\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    555\u001b[0m ):\n\u001b[1;32m    556\u001b[0m     \u001b[39m# do not support partial ROC computation for multiclass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch/lib/python3.10/site-packages/sklearn/utils/validation.py:929\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    927\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m    928\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 929\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    930\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    931\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    932\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    933\u001b[0m         )\n\u001b[1;32m    935\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    936\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x=train_data.x, edge_index=train_data.edge_index)\n",
    "\n",
    "    # sampling training negatives for every training epoch\n",
    "    neg_edge_index = negative_sampling(edge_index=train_data.edge_index,\n",
    "                                        num_nodes=train_data.num_nodes,\n",
    "                                        num_neg_samples=train_data.edge_label_index.size(1), \n",
    "                                        method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    val_auc = eval_link_predictor(model, val_data)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGAE(\n",
       "  (conv1): GCNConv(48, 128)\n",
       "  (conv2): GCNConv(128, 64)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1176, 48], edge_index=[2, 6], edge_label=[0], edge_label_index=[2, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z = model.encode(x=data.x, edge_index=data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   6,   9,  10,  12,  13,  14,  15,  16,  17,  18,  19,  20,\n",
       "          23,  27,  30,  31,  33,  34,  35,  39,  44,  45,  46,  50,  54,  55,\n",
       "          59,  69,  72,  74,  75,  78,  79,  81,  82,  83,  86,  92,  93, 120,\n",
       "         126, 138, 139, 150, 151, 152, 155, 158, 159, 160, 163, 165, 179, 180,\n",
       "         183, 184, 185, 186, 187, 190, 201, 206, 207, 208, 209, 212, 213, 215,\n",
       "         217, 222, 223, 240, 243, 246, 247, 249, 250, 251],\n",
       "        [  6,   6,   7,   7,   7,   8,   8,   8,   8,   8,   8,   9,   9,   9,\n",
       "           9,  10,  11,  11,  11,  11,  11,  12,  13,  13,  13,  14,  15,  15,\n",
       "          15,  17,  18,  18,  18,  19,  19,  19,  19,  19,  20,  21,  21,  26,\n",
       "          27,  29,  29,  31,  31,  31,  31,  32,  32,  32,  33,  33,  35,  36,\n",
       "          36,  36,  36,  37,  37,  37,  39,  40,  40,  40,  40,  41,  41,  41,\n",
       "          42,  43,  43,  46,  46,  47,  47,  47,  47,  47]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.decode(z=z, edge_label_index=data.edge_label_index).view(-1).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_link_predictor(model=model,\n",
    "#                              train_data=train_data,\n",
    "#                              val_data=val_data,\n",
    "#                              optimizer=optimizer,\n",
    "#                              criterion=criterion)\n",
    "\n",
    "test_auc = eval_link_predictor(model, test_data)\n",
    "print(f\"Test: {test_auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bd3325b1e148b7ccd001bb0c3583f22709fd7c160b5925c7aaf985f1c9796e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
